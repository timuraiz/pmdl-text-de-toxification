{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "xl4bz2TgL9OH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/filtered_and_prepocessed.csv'\n"
      ],
      "metadata": {
        "id": "a2CL4Sk5MGw9"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "ffmjYmR8Mq0f"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "AaH7_x4UMzsN",
        "outputId": "69224580-f046-46a0-a57c-de1a99aa519d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           reference  \\\n",
              "0  alkar floods mental waste would explain high l...   \n",
              "1                          youre becoming disgusting   \n",
              "2                                    well spare life   \n",
              "3                                        monkey wake   \n",
              "4                                        orders kill   \n",
              "\n",
              "                                         translation  \n",
              "0  alkar flooding psychic waste explains high lev...  \n",
              "1                                youre getting nasty  \n",
              "2                          well could spare life one  \n",
              "3                           ah monkey youve got snap  \n",
              "4                                 ive got orders put  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6569cacf-da90-437c-a15f-7b8afa8daa53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reference</th>\n",
              "      <th>translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>alkar floods mental waste would explain high l...</td>\n",
              "      <td>alkar flooding psychic waste explains high lev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>youre becoming disgusting</td>\n",
              "      <td>youre getting nasty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well spare life</td>\n",
              "      <td>well could spare life one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>monkey wake</td>\n",
              "      <td>ah monkey youve got snap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>orders kill</td>\n",
              "      <td>ive got orders put</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6569cacf-da90-437c-a15f-7b8afa8daa53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6569cacf-da90-437c-a15f-7b8afa8daa53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6569cacf-da90-437c-a15f-7b8afa8daa53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-834d5131-4669-43ba-8baf-ed2dbb53a021\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-834d5131-4669-43ba-8baf-ed2dbb53a021')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-834d5131-4669-43ba-8baf-ed2dbb53a021 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "aiwN7dSQz-rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = list(data['reference'])\n",
        "target_texts = list(data['translation'])"
      ],
      "metadata": {
        "id": "n9DnR000nOVu"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = list(filter(lambda x: isinstance(x, str), input_texts))[:1000]\n",
        "target_texts = list(filter(lambda x: isinstance(x, str), target_texts))[:1000]"
      ],
      "metadata": {
        "id": "f-gOYieZ7ryA"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "word_counter = Counter()\n",
        "\n",
        "for sentence in input_texts + target_texts:\n",
        "    word_counter.update(sentence.lower().split())\n",
        "\n",
        "\n",
        "vocab = {word: index + 4 for index, word in enumerate(word_counter)}  # +4 for special tokens\n",
        "vocab['<pad>'] = 0\n",
        "vocab['<unk>'] = 1\n",
        "vocab['<eos>'] = 2\n",
        "vocab['<sos>'] = 3\n",
        "\n",
        "# Determine the size of your vocabulary\n",
        "num_tokens = len(vocab)\n",
        "\n",
        "# Function to tokenize sentences\n",
        "def tokenize(sentence, vocab, max_length):\n",
        "    return [vocab.get(token, vocab['<unk>']) for token in sentence.lower().split()[:max_length]]\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, input_texts, target_texts, vocab, max_length=512):\n",
        "        self.input_texts = [torch.tensor(tokenize(text, vocab, max_length)) for text in input_texts]\n",
        "        self.target_texts = [torch.tensor(tokenize(text, vocab, max_length)) for text in target_texts]\n",
        "        self.pad_idx = vocab['<pad>']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_texts[idx], self.target_texts[idx]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        input_texts, target_texts = zip(*batch)\n",
        "        # Padding sequences to the max length in each batch\n",
        "        input_texts = pad_sequence(input_texts, batch_first=True, padding_value=self.pad_idx)\n",
        "        target_texts = pad_sequence(target_texts, batch_first=True, padding_value=self.pad_idx)\n",
        "        return input_texts, target_texts\n",
        "\n",
        "# Split the dataset\n",
        "input_train, input_val, target_train, target_val = train_test_split(input_texts, target_texts, test_size=0.1)\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = TextDataset(input_train, target_train, vocab, max_length=500)\n",
        "val_dataset = TextDataset(input_val, target_val, vocab, max_length=500)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, collate_fn=val_dataset.collate_fn)\n",
        "\n"
      ],
      "metadata": {
        "id": "6XnAnwG7nh31"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSdDS4wz8YCQ",
        "outputId": "e59ca0be-a989-40b4-c3f1-20ed0f3bc337"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alkar': 4, 'floods': 5, 'mental': 6, 'waste': 7, 'would': 8, 'explain': 9, 'high': 10, 'levels': 11, 'neurotransmitter': 12, 'youre': 13, 'becoming': 14, 'disgusting': 15, 'well': 16, 'spare': 17, 'life': 18, 'monkey': 19, 'wake': 20, 'orders': 21, 'kill': 22, 'im': 23, 'gon': 24, 'na': 25, 'child': 26, 'genetic': 27, 'disorder': 28, 'whos': 29, 'die': 30, 'l': 31, 'theyre': 32, 'laughing': 33, 'us': 34, 'kick': 35, 'ass': 36, 'maine': 37, 'short': 38, 'black': 39, 'people': 40, 'back': 41, 'briggs': 42, 'hell': 43, 'going': 44, 'another': 45, 'simply': 46, 'didnt': 47, 'know': 48, 'whenever': 49, 'met': 50, 'brother': 51, 'nearly': 52, 'beat': 53, 'shit': 54, 'youd': 55, 'probably': 56, 'want': 57, 'buy': 58, 'chocolates': 59, 'flowers': 60, 'whispered': 61, 'pretty': 62, 'rubbish': 63, 'spirits': 64, 'cursed': 65, 'walking': 66, 'roads': 67, 'waterways': 68, 'find': 69, 'unfaithful': 70, 'man': 71, 'never': 72, 'seen': 73, 'ill': 74, 'freeze': 75, 'come': 76, 'cal': 77, 'leave': 78, 'alone': 79, 'hes': 80, 'tallest': 81, 'son': 82, 'bitch': 83, 'dating': 84, 'alex': 85, 'harris': 86, 'swore': 87, 'id': 88, 'rather': 89, 'go': 90, 'loser': 91, 'famous': 92, 'dead': 93, 'quote': 94, 'jake': 95, 'oppenheimer': 96, 'must': 97, 'feel': 98, 'like': 99, 'terrible': 100, 'god': 101, 'could': 102, 'keep': 103, 'mouth': 104, 'shut': 105, 'miss': 106, 'opulent': 107, 'said': 108, 'moist': 109, 'murder': 110, 'order': 111, 'foolish': 112, 'xerxes': 113, 'calmly': 114, 'passed': 115, 'control': 116, 'computer': 117, 'network': 118, 'commanded': 119, 'handle': 120, 'kind': 121, 'trouble': 122, 'night': 123, 'lil': 124, 'dice': 125, 'satisfied': 126, 'thirst': 127, 'though': 128, 'knew': 129, 'shaggy': 130, 'forgive': 131, 'real': 132, 'starts': 133, 'first': 134, 'time': 135, 'fuck': 136, 'kid': 137, 'think': 138, 'weirdest': 139, 'person': 140, 'ive': 141, 'ever': 142, 'mean': 143, 'fucking': 144, 'crazy': 145, 'talking': 146, 'one': 147, 'cant': 148, 'even': 149, 'pronounce': 150, 'trying': 151, 'drugged': 152, 'dont': 153, 'whats': 154, 'porn': 155, 'comes': 156, 'home': 157, 'hey': 158, 'poor': 159, 'bastard': 160, 'bad': 161, 'news': 162, 'miserable': 163, 'hitting': 164, 'boyfriend': 165, 'girl': 166, 'murray': 167, 'eyes': 168, 'see': 169, 'problem': 170, 'day': 171, 'glenda': 172, 'says': 173, 'used': 174, 'anything': 175, 'better': 176, 'nothing': 177, 'matter': 178, 'reasons': 179, 'company': 180, 'incompetent': 181, 'understand': 182, 'got': 183, 'grievances': 184, 'fools': 185, 'need': 186, 'talk': 187, 'police': 188, 'air': 189, 'rot': 190, 'front': 191, 'cameras': 192, 'killer': 193, 'tell': 194, 'elena': 195, 'doesnt': 196, 'pick': 197, 'phone': 198, 'weil': 199, 'helped': 200, 'morals': 201, 'integrity': 202, 'considerable': 203, 'reward': 204, 'head': 205, 'content': 206, 'merely': 207, 'killing': 208, 'count': 209, 'sisters': 210, 'savage': 211, 'brood': 212, 'mutilated': 213, 'body': 214, 'contemptuously': 215, 'deposited': 216, 'castle': 217, 'gate': 218, 'told': 219, 'swear': 220, 'best': 221, 'thing': 222, 'save': 223, 'little': 224, 'ashamed': 225, 'blob': 226, 'wan': 227, 'happens': 228, 'thats': 229, 'bored': 230, 'witless': 231, 'two': 232, 'granny': 233, 'long': 234, 'work': 235, 'patrons': 236, 'screwed': 237, 'guy': 238, 'totally': 239, 'irresponsible': 240, 'funny': 241, 'nazis': 242, 'always': 243, 'guys': 244, 'mustve': 245, 'pissed': 246, 'damn': 247, 'straight': 248, 'believe': 249, 'marcies': 250, 'gone': 251, 'new': 252, 'press': 253, 'secretary': 254, 'describing': 255, 'dopey': 256, 'chop': 257, 'smelling': 258, 'right': 259, 'shes': 260, 'devils': 261, 'maid': 262, 'anal': 263, 'dabble': 264, 'chest': 265, 'week': 266, 'month': 267, 'crotch': 268, 'half': 269, 'travis': 270, 'someones': 271, 'getting': 272, 'nuts': 273, 'drown': 274, 'burn': 275, 'girlfriends': 276, 'crime': 277, 'committed': 278, 'standing': 279, 'mcbride': 280, 'mikael': 281, 'braver': 282, 'foolhardy': 283, 'nolans': 284, 'destroyed': 285, 'less': 286, 'crap': 287, 'mostly': 288, 'hope': 289, 'piss': 290, 'mountain': 291, 'chumps': 292, 'isnt': 293, 'fitting': 294, 'send': 295, 'oneyear': 296, 'chip': 297, 'away': 298, 'anonymous': 299, 'sexual': 300, 'maniacs': 301, 'bloody': 302, 'england': 303, 'really': 304, 'charles': 305, 'taking': 306, 'swill': 307, 'beer': 308, 'wouldnt': 309, 'last': 310, 'minutes': 311, 'leading': 312, 'outfit': 313, 'wasnt': 314, 'rotten': 315, 'drinking': 316, 'gambling': 317, 'womanizing': 318, 'putting': 319, 'stalker': 320, 'stupid': 321, 'college': 322, 'counselor': 323, 'couldnt': 324, 'get': 325, 'competition': 326, 'make': 327, 'sure': 328, 'ariadne': 329, 'ray': 330, 'fight': 331, 'hurt': 332, 'clearly': 333, 'delusional': 334, 'psychotic': 335, 'bring': 336, 'malik': 337, 'crybaby': 338, 'reminded': 339, 'ten': 340, 'niggers': 341, 'nursery': 342, 'rhyme': 343, 'ta': 344, 'admit': 345, 'memories': 346, 'happened': 347, 'let': 348, 'filthy': 349, 'grezu': 350, 'paw': 351, 'way': 352, 'ethan': 353, 'thanks': 354, 'hole': 355, 'case': 356, 'natasha': 357, 'whore': 358, 'elsewhere': 359, 'okay': 360, 'mort': 361, 'put': 362, 'blender': 363, 'somebody': 364, 'rob': 365, 'end': 366, 'motherfucker': 367, 'latino': 368, 'annoying': 369, 'look': 370, 'pussy': 371, 'kicking': 372, 'latin': 373, 'name': 374, 'arrogant': 375, 'sickness': 376, 'elites': 377, 'throughout': 378, 'history': 379, 'literal': 380, 'cases': 381, 'figurative': 382, 'ivory': 383, 'towers': 384, 'taken': 385, 'crummy': 386, 'cashiers': 387, 'job': 388, 'survival': 389, 'wants': 390, 'survive': 391, 'world': 392, 'rape': 393, 'whistle': 394, 'huh': 395, 'metal': 396, 'anvil': 397, 'lung': 398, 'prevent': 399, 'dying': 400, 'thought': 401, 'bitterly': 402, 'turned': 403, 'alarm': 404, 'sleep': 405, 'glad': 406, 'town': 407, 'yeah': 408, 'instead': 409, 'feed': 410, 'may': 411, 'chosen': 412, 'career': 413, 'okwe': 414, 'fucked': 415, 'walk': 416, 'hair': 417, 'glasses': 418, 'great': 419, 'bonsal': 420, 'suicide': 421, 'attack': 422, 'rest': 423, 'mr': 424, 'president': 425, 'distinguished': 426, 'visitors': 427, 'honorable': 428, 'senators': 429, 'indians': 430, 'await': 431, 'damnmani': 432, 'wanted': 433, 'old': 434, 'football': 435, 'coachman': 436, 'door': 437, 'car': 438, 'jerk': 439, 'johnny': 440, 'cinque': 441, 'fool': 442, 'sit': 443, 'around': 444, 'highfive': 445, 'big': 446, 'joke': 447, 'buddy': 448, 'drove': 449, 'road': 450, 'check': 451, 'citys': 452, 'paying': 453, 'filing': 454, 'chapter': 455, 'drive': 456, 'bus': 457, 'passengers': 458, 'river': 459, 'bukowski': 460, 'cut': 461, 'theres': 462, 'enough': 463, 'say': 464, 'within': 465, 'months': 466, 'least': 467, 'boy': 468, 'jack': 469, 'close': 470, 'gettin': 471, 'tit': 472, 'caught': 473, 'ringer': 474, 'alive': 475, 'alan': 476, 'annieoh': 477, 'human': 478, 'race': 479, 'smelly': 480, 'camp': 481, 'looked': 482, 'forever': 483, 'times': 484, 'sort': 485, 'hoped': 486, 'starve': 487, 'death': 488, 'helping': 489, 'good': 490, 'theyll': 491, 'shoot': 492, 'mallory': 493, 'assured': 494, 'run': 495, 'parking': 496, 'lot': 497, 'slopey': 498, 'ratcliffe': 499, 'powerful': 500, 'dreadful': 501, 'wizard': 502, 'neednt': 503, 'worry': 504, 'simple': 505, 'hermit': 506, 'youll': 507, 'agree': 508, 'every': 509, 'bottom': 510, 'waiting': 511, 'oldfashioned': 512, 'flow': 513, 'cocaine': 514, 'alzheimers': 515, 'blow': 516, 'brains': 517, 'freak': 518, 'jailfor': 519, 'bullshit': 520, 'aint': 521, 'anywhere': 522, 'liar': 523, 'hours': 524, 'place': 525, 'crawling': 526, 'zandozans': 527, 'microscopic': 528, 'minds': 529, 'rogan': 530, 'try': 531, 'shot': 532, 'birthday': 533, 'present': 534, 'fat': 535, 'cats': 536, 'wife': 537, 'foreign': 538, 'affairs': 539, 'clennam': 540, 'certainly': 541, 'support': 542, 'many': 543, 'scoundrels': 544, 'nut': 545, 'lives': 546, 'today': 547, 'district': 548, 'seized': 549, 'matches': 550, 'description': 551, 'oh': 552, 'goddamn': 553, 'vision': 554, 'howard': 555, 'fannying': 556, 'internal': 557, 'motivation': 558, 'mate': 559, 'shout': 560, 'dad': 561, 'give': 562, 'face': 563, 'side': 564, 'aware': 565, 'lack': 566, 'selfrespect': 567, 'useless': 568, 'failure': 569, 'something': 570, 'fuckin': 571, 'soap': 572, 'finished': 573, 'towel': 574, 'maxipad': 575, 'freaky': 576, 'havent': 577, 'years': 578, 'nine': 579, 'three': 580, 'weeks': 581, 'means': 582, 'noodles': 583, 'youve': 584, 'hiding': 585, 'asshole': 586, 'found': 587, 'drink': 588, 'whose': 589, 'mother': 590, 'gave': 591, 'rid': 592, 'inside': 593, 'hit': 594, 'hard': 595, 'fast': 596, 'young': 597, 'con': 598, 'stealing': 599, 'yorks': 600, 'wealthy': 601, 'honey': 602, 'donkey': 603, 'pull': 604, 'calm': 605, 'scream': 606, 'faster': 607, 'bleed': 608, 'midst': 609, 'cold': 610, 'reach': 611, 'washaving': 612, 'sex': 613, 'killed': 614, 'live': 615, 'monster': 616, 'restraint': 617, 'staged': 618, 'penthouse': 619, 'assaulted': 620, 'making': 621, 'burned': 622, 'queen': 623, 'might': 624, 'lose': 625, 'license': 626, 'client': 627, 'vindictive': 628, 'bitter': 629, 'woman': 630, 'love': 631, 'men': 632, 'gay': 633, 'help': 634, 'cunt': 635, 'smell': 636, 'lady': 637, 'wetness': 638, 'made': 639, 'reckon': 640, 'flat': 641, 'impatient': 642, 'bugger': 643, 'stanley': 644, 'rasped': 645, 'listen': 646, 'carlos': 647, 'sanchez': 648, 'course': 649, 'hed': 650, 'nice': 651, 'things': 652, 'painful': 653, 'experiences': 654, 'mom': 655, 'promoting': 656, 'book': 657, 'wrote': 658, 'hooker': 659, 'crush': 660, 'camellia': 661, 'japonica': 662, 'holy': 663, 'stop': 664, 'idiot': 665, 'hyena': 666, 'cousins': 667, 'david': 668, 'dumped': 669, 'senor': 670, 'frogs': 671, 'horrifying': 672, 'places': 673, 'known': 674, 'farmer': 675, 'unstable': 676, 'irrational': 677, 'overall': 678, 'health': 679, 'questionable': 680, 'forgot': 681, 'goddam': 682, 'gun': 683, 'pencil': 684, 'rubber': 685, 'stuck': 686, 'bin': 687, 'ladens': 688, 'breast': 689, 'scratch': 690, 'signaling': 691, 'scared': 692, 'shitless': 693, 'tenente': 694, 'stole': 695, 'jokes': 696, 'dumbass': 697, 'hot': 698, 'cup': 699, 'coffee': 700, 'meal': 701, 'often': 702, 'beyond': 703, 'worried': 704, 'mess': 705, 'arent': 706, 'mind': 707, 'officer': 708, 'please': 709, 'spider': 710, 'trapped': 711, 'force': 712, 'consume': 713, 'large': 714, 'quantity': 715, 'fermented': 716, 'wheat': 717, 'ridiculous': 718, 'pearl': 719, 'harbor': 720, 'use': 721, 'gas': 722, 'everybody': 723, 'silly': 724, 'backpack': 725, 'steal': 726, 'avoid': 727, 'question': 728, 'joe': 729, 'cops': 730, 'full': 731, 'prostitutes': 732, 'outside': 733, 'airport': 734, 'final': 735, 'five': 736, 'lesbians': 737, 'seems': 738, 'albatross': 739, 'throws': 740, 'hands': 741, 'neck': 742, 'decided': 743, 'delacroix': 744, 'needed': 745, 'guardian': 746, 'angel': 747, 'decreed': 748, 'wisdom': 749, 'mouse': 750, 'rat': 751, 'homicidal': 752, 'friend': 753, 'louisiana': 754, 'trooper': 755, 'limped': 756, 'drawing': 757, 'revolver': 758, 'webbing': 759, 'holster': 760, 'animal': 761, 'money': 762, 'watch': 763, 'bigger': 764, 'movie': 765, 'crawled': 766, 'sewer': 767, 'horrible': 768, 'jumping': 769, 'throwing': 770, 'typ': 771, 'generator': 772, 'strong': 773, 'boost': 774, 'thighs': 775, 'massive': 776, 'orgasm': 777, 'secret': 778, 'skin': 779, 'silence': 780, 'project': 781, 'either': 782, 'drugs': 783, 'compromised': 784, 'created': 785, 'rain': 786, 'stuffed': 787, 'values': 788, 'throats': 789, 'frodo': 790, 'feeling': 791, 'strangely': 792, 'rural': 793, 'ignorant': 794, 'stopped': 795, 'overwhelmed': 796, 'ridiculousness': 797, 'discussion': 798, 'sir': 799, 'basil': 800, 'giving': 801, 'british': 802, 'diplomatic': 803, 'fuckyou': 804, 'passport': 805, 'marriage': 806, 'shave': 807, 'sits': 808, 'toilet': 809, 'cuts': 810, 'nails': 811, 'legs': 812, 'sometimes': 813, 'showing': 814, 'march': 815, 'spain': 816, 'trample': 817, 'king': 818, 'philip': 819, 'dust': 820, 'whatd': 821, 'ugly': 822, 'sick': 823, 'tired': 824, 'theyve': 825, 'sucking': 826, 'blood': 827, 'since': 828, 'insults': 829, 'rookie': 830, 'still': 831, 'shits': 832, 'lawn': 833, 'jump': 834, 'circle': 835, 'start': 836, 'shaking': 837, 'tits': 838, 'wow': 839, 'trash': 840, 'team': 841, 'clean': 842, 'bathroom': 843, 'fernandez': 844, 'picked': 845, 'martha': 846, 'becks': 847, 'smear': 848, 'lonely': 849, 'hearts': 850, 'rag': 851, 'shed': 852, 'already': 853, 'greedy': 854, 'selfish': 855, 'maybe': 856, 'lost': 857, 'faith': 858, 'screw': 859, 'married': 860, 'bipolar': 861, 'drug': 862, 'addict': 863, 'easy': 864, 'mutilate': 865, 'corpses': 866, 'genius': 867, 'skirt': 868, 'baby': 869, 'none': 870, 'tastes': 871, 'crappy': 872, 'hang': 873, 'someone': 874, 'thinks': 875, 'wed': 876, 'surprised': 877, 'banged': 878, 'deserve': 879, 'slammed': 880, 'nose': 881, 'coyotes': 882, 'uncle': 883, 'giambis': 884, 'worst': 885, 'baseman': 886, 'baseball': 887, 'mend': 888, 'receiving': 889, 'losers': 890, 'forget': 891, 'asking': 892, 'pussyatthestation': 893, 'daughter': 894, 'witch': 895, 'inject': 896, 'pin': 897, 'thets': 898, 'sister': 899, 'ejaculated': 900, 'saw': 901, 'caitlins': 902, 'junk': 903, 'pimps': 904, 'thugs': 905, 'junkies': 906, 'la': 907, 'servants': 908, 'animals': 909, 'fought': 910, 'together': 911, 'stabbed': 912, 'marauders': 913, 'selling': 914, 'yes': 915, 'bury': 916, 'fate': 917, 'gods': 918, 'done': 919, 'country': 920, 'butt': 921, 'water': 922, 'drop': 923, 'yup': 924, 'holiday': 925, 'sucks': 926, 'fire': 927, 'break': 928, 'arm': 929, 'knows': 930, 'ready': 931, 'nasty': 932, 'charlie': 933, 'bay': 934, 'heels': 935, 'lunge': 936, 'ground': 937, 'sooner': 938, 'later': 939, 'wills': 940, 'called': 941, 'drone': 942, 'idiots': 943, 'pregnant': 944, 'worth': 945, 'pig': 946, 'spit': 947, 'goes': 948, 'london': 949, 'sandwiches': 950, 'finally': 951, 'paul': 952, 'devil': 953, 'ok': 954, 'cherry': 955, 'suck': 956, 'cock': 957, 'quite': 958, 'excitement': 959, 'thank': 960, 'turns': 961, 'math': 962, 'grab': 963, 'dick': 964, 'friggin': 965, 'shelter': 966, 'mural': 967, 'museum': 968, 'art': 969, 'jacki': 970, 'marrying': 971, 'rhys': 972, 'bitches': 973, 'show': 974, 'beautiful': 975, 'bloke': 976, 'anyone': 977, 'bugs': 978, 'random': 979, 'act': 980, 'violence': 981, 'normal': 982, 'living': 983, 'cowards': 984, 'walter': 985, 'biggest': 986, 'worm': 987, 'take': 988, 'lake': 989, 'thousand': 990, 'warriors': 991, 'genocide': 992, 'damned': 993, 'contest': 994, 'sheryl': 995, 'tanis': 996, 'murmured': 997, 'mad': 998, 'bull': 999, 'houston': 1000, 'praising': 1001, 'raped': 1002, 'twice': 1003, 'father': 1004, 'win': 1005, 'wimp': 1006, 'fun': 1007, 'shitty': 1008, 'sun': 1009, 'kidnap': 1010, 'raise': 1011, 'woods': 1012, 'behind': 1013, 'everything': 1014, 'throw': 1015, 'dormitory': 1016, 'slut': 1017, 'sorry': 1018, 'pie': 1019, 'sweatshirt': 1020, 'next': 1021, 'hour': 1022, 'midget': 1023, 'frankly': 1024, 'whether': 1025, 'else': 1026, 'pit': 1027, 'sabbath': 1028, 'friends': 1029, 'jizz': 1030, 'letting': 1031, 'variety': 1032, 'print': 1033, 'story': 1034, 'rights': 1035, 'certain': 1036, 'type': 1037, 'thinker': 1038, 'sweeper': 1039, 'personal': 1040, 'insult': 1041, 'formal': 1042, 'education': 1043, 'official': 1044, 'status': 1045, 'incredible': 1046, 'successes': 1047, 'heard': 1048, 'rich': 1049, 'justcall': 1050, 'eccentric': 1051, 'dies': 1052, 'pile': 1053, 'ash': 1054, 'hear': 1055, 'kim': 1056, 'jongun': 1057, 'pooed': 1058, 'pants': 1059, 'notgoing': 1060, 'interesting': 1061, 'sent': 1062, 'africanamerican': 1063, 'homosexual': 1064, 'whoever': 1065, 'patrices': 1066, 'grandmothers': 1067, 'gospel': 1068, 'brunch': 1069, 'jackie': 1070, 'cruel': 1071, 'bullies': 1072, 'treat': 1073, 'pariah': 1074, 'kirk': 1075, 'true': 1076, 'erotic': 1077, 'adventurer': 1078, 'deranged': 1079, 'herman': 1080, 'nervous': 1081, 'spoke': 1082, 'bellowing': 1083, 'pal': 1084, 'voice': 1085, 'doodlydamn': 1086, 'marty': 1087, 'bitty': 1088, 'sensitivity': 1089, 'misery': 1090, 'strelnikov': 1091, 'heart': 1092, 'window': 1093, 'revolutionary': 1094, 'bullet': 1095, 'trunk': 1096, 'gangster': 1097, 'needs': 1098, 'ransom': 1099, 'lets': 1100, 'logically': 1101, 'answer': 1102, 'questions': 1103, 'electric': 1104, 'shock': 1105, 'enemy': 1106, 'open': 1107, 'liked': 1108, 'invitation': 1109, 'feet': 1110, 'saying': 1111, 'garbage': 1112, 'upstairs': 1113, 'brush': 1114, 'fangs': 1115, 'icicles': 1116, 'hanging': 1117, 'bitchs': 1118, 'ears': 1119, 'different': 1120, 'housework': 1121, 'peoples': 1122, 'scientific': 1123, 'psychology': 1124, 'much': 1125, 'voters': 1126, 'swallow': 1127, 'notice': 1128, 'finish': 1129, 'gangs': 1130, 'sleeping': 1131, 'dump': 1132, 'solution': 1133, 'spread': 1134, 'buggers': 1135, 'hoofs': 1136, 'game': 1137, 'upon': 1138, 'exec': 1139, 'feelings': 1140, 'duty': 1141, 'thief': 1142, 'realize': 1143, 'strangled': 1144, 'cavity': 1145, 'free': 1146, 'mkay': 1147, 'plaque': 1148, 'building': 1149, 'teeth': 1150, 'excuse': 1151, 'almost': 1152, 'dwl': 1153, 'afford': 1154, 'speeding': 1155, 'ticket': 1156, 'ordering': 1157, 'strike': 1158, 'harry': 1159, 'stick': 1160, 'space': 1161, 'ship': 1162, 'wait': 1163, 'serving': 1164, 'marines': 1165, 'marry': 1166, 'important': 1167, 'precious': 1168, 'richie': 1169, 'saint': 1170, 'hewel': 1171, 'tried': 1172, 'apparently': 1173, 'taught': 1174, 'lester': 1175, 'loved': 1176, 'part': 1177, 'lips': 1178, 'tiniest': 1179, 'bit': 1180, 'kissed': 1181, 'group': 1182, 'attention': 1183, 'ant': 1184, 'individuals': 1185, 'supposed': 1186, 'difference': 1187, 'luca': 1188, 'somewhere': 1189, 'threw': 1190, 'gets': 1191, 'mixed': 1192, 'sovereign': 1193, 'army': 1194, 'ends': 1195, 'prison': 1196, 'somalis': 1197, 'came': 1198, 'guns': 1199, 'shooting': 1200, 'american': 1201, 'temper': 1202, 'lately': 1203, 'lois': 1204, 'punching': 1205, 'white': 1206, 'latest': 1207, 'edition': 1208, 'dsm': 1209, 'listed': 1210, 'psychiatric': 1211, 'association': 1212, 'transsexuals': 1213, 'classified': 1214, 'illness': 1215, 'tubman': 1216, 'toss': 1217, 'miscreants': 1218, 'laughed': 1219, 'brits': 1220, 'desert': 1221, 'wear': 1222, 'shorts': 1223, 'makes': 1224, 'shaftoe': 1225, 'punch': 1226, 'inspires': 1227, 'respect': 1228, 'knowing': 1229, 'absolute': 1230, 'believed': 1231, 'pressure': 1232, 'beneath': 1233, 'buttocks': 1234, 'perhaps': 1235, 'shoulders': 1236, 'weirdo': 1237, 'hari': 1238, 'suggest': 1239, 'risked': 1240, 'sake': 1241, 'pursuit': 1242, 'glory': 1243, 'offensive': 1244, 'survived': 1245, 'chili': 1246, 'waitress': 1247, 'goofy': 1248, 'pervert': 1249, 'executed': 1250, 'victimized': 1251, 'bandages': 1252, 'talkin': 1253, 'dunham': 1254, 'cunts': 1255, 'pay': 1256, 'murraywell': 1257, 'fbi': 1258, 'director': 1259, 'serious': 1260, 'organization': 1261, 'disapprove': 1262, 'red': 1263, 'wine': 1264, 'quarter': 1265, 'wooden': 1266, 'spoon': 1267, 'deglaze': 1268, 'frying': 1269, 'pan': 1270, 'mortal': 1271, 'eliminate': 1272, 'fidgety': 1273, 'lunch': 1274, 'eat': 1275, 'pork': 1276, 'sandwich': 1277, 'sunday': 1278, 'cleaning': 1279, 'slop': 1280, 'left': 1281, 'jay': 1282, 'pawn': 1283, 'shop': 1284, 'prompt': 1285, 'family': 1286, 'nothingsbeen': 1287, 'touched': 1288, 'filth': 1289, 'wont': 1290, 'torment': 1291, 'ones': 1292, 'fly': 1293, 'block': 1294, 'crying': 1295, 'sought': 1296, 'rotters': 1297, 'mcfee': 1298, 'served': 1299, 'ugh': 1300, 'lockwood': 1301, 'cellar': 1302, 'reeks': 1303, 'wet': 1304, 'dog': 1305, 'sacrifice': 1306, 'thatll': 1307, 'prove': 1308, 'theory': 1309, 'relationships': 1310, 'conditional': 1311, 'connection': 1312, 'whatever': 1313, 'maze': 1314, 'brain': 1315, 'satellite': 1316, 'meat': 1317, 'move': 1318, 'seat': 1319, 'maam': 1320, 'fork': 1321, 'eye': 1322, 'hadnt': 1323, 'insane': 1324, 'assessment': 1325, 'ron': 1326, 'stay': 1327, 'whole': 1328, 'screwing': 1329, 'germans': 1330, 'cares': 1331, 'year': 1332, 'north': 1333, 'korea': 1334, 'soon': 1335, 'holly': 1336, 'figgins': 1337, 'pedro': 1338, 'sam': 1339, 'happy': 1340, 'metallic': 1341, 'fanny': 1342, 'catch': 1343, 'following': 1344, 'dummy': 1345, 'raid': 1346, 'liquor': 1347, 'store': 1348, 'meantime': 1349, 'everyones': 1350, 'betting': 1351, 'trees': 1352, 'thousandyearold': 1353, 'snake': 1354, 'demon': 1355, 'guts': 1356, 'wash': 1357, 'destroy': 1358, 'coincidence': 1359, 'coach': 1360, 'single': 1361, 'pathetic': 1362, 'kneecaps': 1363, 'destruction': 1364, 'everyone': 1365, 'exploiting': 1366, 'abused': 1367, 'age': 1368, 'slaughtered': 1369, 'ox': 1370, 'drives': 1371, 'naked': 1372, 'knight': 1373, 'obviously': 1374, 'dirty': 1375, 'tormented': 1376, 'jealousy': 1377, 'liewhiz': 1378, 'forehand': 1379, 'pussycat': 1380, 'despair': 1381, 'commandsmurder': 1382, 'desecrate': 1383, 'titty': 1384, 'exclamation': 1385, 'points': 1386, 'mrs': 1387, 'solis': 1388, 'stink': 1389, 'lessons': 1390, 'york': 1391, 'percocet': 1392, 'uh': 1393, 'school': 1394, 'freshman': 1395, 'boys': 1396, 'finds': 1397, 'kills': 1398, 'jim': 1399, 'far': 1400, 'risk': 1401, 'stunts': 1402, 'parents': 1403, 'jose': 1404, 'mention': 1405, 'business': 1406, 'pack': 1407, 'lies': 1408, 'hypocrisy': 1409, 'smart': 1410, 'dumb': 1411, 'pretending': 1412, 'slimy': 1413, 'document': 1414, 'significance': 1415, 'tom': 1416, 'future': 1417, 'generations': 1418, 'readers': 1419, 'basis': 1420, 'novel': 1421, 'indeed': 1422, 'trilogy': 1423, 'commit': 1424, 'although': 1425, 'moment': 1426, 'weakness': 1427, 'womens': 1428, 'stinks': 1429, 'darling': 1430, 'crushed': 1431, 'cross': 1432, 'runes': 1433, 'corpse': 1434, 'crimes': 1435, 'daniel': 1436, 'expect': 1437, 'call': 1438, 'sickest': 1439, 'rafe': 1440, 'picking': 1441, 'innocent': 1442, 'scare': 1443, 'experience': 1444, 'derail': 1445, 'entire': 1446, 'earth': 1447, 'pritkins': 1448, 'comedians': 1449, 'dress': 1450, 'savages': 1451, 'pipe': 1452, 'number': 1453, 'dimwit': 1454, 'board': 1455, 'graham': 1456, 'chances': 1457, 'spawning': 1458, 'descendants': 1459, 'virtually': 1460, 'nil': 1461, 'pamplona': 1462, 'stamped': 1463, 'testicle': 1464, 'meg': 1465, 'threats': 1466, 'chicken': 1467, 'cover': 1468, 'hump': 1469, 'frankie': 1470, 'died': 1471, 'jerking': 1472, 'patience': 1473, 'resources': 1474, 'department': 1475, 'illegal': 1476, 'hire': 1477, 'bunch': 1478, 'cause': 1479, 'discrimination': 1480, 'soy': 1481, 'milk': 1482, 'suppose': 1483, 'medal': 1484, 'billy': 1485, 'trust': 1486, 'suffering': 1487, 'pain': 1488, 'fall': 1489, 'disgrace': 1490, 'four': 1491, 'tops': 1492, 'hate': 1493, 'raven': 1494, 'society': 1495, 'brought': 1496, 'chocolate': 1497, 'penises': 1498, 'line': 1499, 'cosgrove': 1500, 'inmate': 1501, 'escaped': 1502, 'eight': 1503, 'husband': 1504, 'essen': 1505, 'kiss': 1506, 'lived': 1507, 'without': 1508, 'lamp': 1509, 'aim': 1510, 'drunk': 1511, 'puppies': 1512, 'meet': 1513, 'opened': 1514, 'given': 1515, 'mere': 1516, 'nipple': 1517, 'ago': 1518, 'jean': 1519, 'follow': 1520, 'enchanting': 1521, 'leader': 1522, 'average': 1523, 'general': 1524, 'defeat': 1525, 'doddering': 1526, 'bag': 1527, 'bones': 1528, 'six': 1529, 'buisson': 1530, 'suspects': 1531, 'ah': 1532, 'word': 1533, 'piece': 1534, 'valdon': 1535, 'typical': 1536, 'western': 1537, 'hero': 1538, 'lift': 1539, 'lump': 1540, 'humiliate': 1541, 'tony': 1542, 'bernie': 1543, 'mobster': 1544, 'faggot': 1545, 'eunik': 1546, 'sluggish': 1547, 'flower': 1548, 'cute': 1549, 'kitten': 1550, 'painted': 1551, 'mermaid': 1552, 'fucks': 1553, 'selfsatisfied': 1554, 'ancestors': 1555, 'prevented': 1556, 'catastrophe': 1557, 'tricks': 1558, 'yearold': 1559, 'latinum': 1560, 'knee': 1561, 'revenge': 1562, 'copper': 1563, 'snapped': 1564, 'sharply': 1565, 'carrying': 1566, 'miles': 1567, 'motherofabitch': 1568, 'signs': 1569, 'wandered': 1570, 'seven': 1571, 'intelligence': 1572, 'nigger': 1573, 'food': 1574, 'cos': 1575, 'cockroach': 1576, 'mine': 1577, 'size': 1578, 'slave': 1579, 'nobody': 1580, 'holding': 1581, 'doors': 1582, 'vera': 1583, 'donovan': 1584, 'intend': 1585, 'prick': 1586, 'worked': 1587, 'bites': 1588, 'dammit': 1589, 'ben': 1590, 'operations': 1591, 'toxin': 1592, 'triggered': 1593, 'ew': 1594, 'overreacted': 1595, 'stating': 1596, 'also': 1597, 'glass': 1598, 'wrists': 1599, 'hells': 1600, 'crowd': 1601, 'chet': 1602, 'gold': 1603, 'silver': 1604, 'jewelry': 1605, 'pussies': 1606, 'pigeons': 1607, 'juniper': 1608, 'madyna': 1609, 'bridegroom': 1610, 'wrong': 1611, 'decision': 1612, 'ruined': 1613, 'skinner': 1614, 'tellin': 1615, 'slippery': 1616, 'went': 1617, 'grabbed': 1618, 'jerked': 1619, 'tinkering': 1620, 'interrupt': 1621, 'pool': 1622, 'balls': 1623, 'plenary': 1624, 'acting': 1625, 'dogs': 1626, 'kinds': 1627, 'bulldogs': 1628, 'skyeterriers': 1629, 'brown': 1630, 'english': 1631, 'terriers': 1632, 'bastards': 1633, 'doin': 1634, 'carpenter': 1635, 'point': 1636, 'war': 1637, 'stab': 1638, 'horns': 1639, 'hello': 1640, 'doofus': 1641, 'jerkoff': 1642, 'reporter': 1643, 'camera': 1644, 'crew': 1645, 'waltzes': 1646, 'hideout': 1647, 'interviews': 1648, 'salvadorans': 1649, 'cop': 1650, 'ran': 1651, 'rode': 1652, 'past': 1653, 'gibraltars': 1654, 'rock': 1655, 'took': 1656, 'tune': 1657, 'fine': 1658, 'knees': 1659, 'faint': 1660, 'thas': 1661, 'acts': 1662, 'deep': 1663, 'guysix': 1664, 'ways': 1665, 'mainland': 1666, 'arab': 1667, 'spend': 1668, 'looking': 1669, 'sweaty': 1670, 'ni': 1671, 'virgin': 1672, 'hide': 1673, 'prostitute': 1674, 'witches': 1675, 'playing': 1676, 'dressup': 1677, 'girls': 1678, 'drinks': 1679, 'kevin': 1680, 'missing': 1681, 'awol': 1682, 'freeborn': 1683, 'utterly': 1684, 'wish': 1685, 'housecoat': 1686, 'killers': 1687, 'care': 1688, 'friday': 1689, 'someday': 1690, 'hotter': 1691, 'girlfriend': 1692, 'weight': 1693, 'maddox': 1694, 'hardon': 1695, 'spat': 1696, 'defined': 1697, 'excessive': 1698, 'masturbation': 1699, 'frequent': 1700, 'indulge': 1701, 'justifying': 1702, 'current': 1703, 'habit': 1704, 'personality': 1705, 'looks': 1706, 'excess': 1707, 'elbow': 1708, 'slapped': 1709, 'groin': 1710, 'nick': 1711, 'cage': 1712, 'leaving': 1713, 'las': 1714, 'vegas': 1715, 'except': 1716, 'elisabeth': 1717, 'shue': 1718, 'set': 1719, 'foot': 1720, 'roldem': 1721, 'instantly': 1722, 'el': 1723, 'grossos': 1724, 'narc': 1725, 'cars': 1726, 'lower': 1727, 'phasers': 1728, 'barry': 1729, 'broke': 1730, 'jesus': 1731, 'maniac': 1732, 'robbed': 1733, 'bank': 1734, 'yet': 1735, 'lend': 1736, 'sword': 1737, 'traitor': 1738, 'errin': 1739, 'wives': 1740, 'play': 1741, 'ping': 1742, 'pong': 1743, 'middle': 1744, 'effeminate': 1745, 'grandchild': 1746, 'shipment': 1747, 'till': 1748, 'writing': 1749, 'orangey': 1750, 'meeting': 1751, 'cried': 1752, 'screamed': 1753, 'slap': 1754, 'lock': 1755, 'house': 1756, 'fatsteps': 1757, 'likes': 1758, 'unser': 1759, 'feeding': 1760, 'ii': 1761, 'saved': 1762, 'parasites': 1763, 'surgically': 1764, 'wallet': 1765, 'cabin': 1766, 'makeup': 1767, 'kept': 1768, 'crate': 1769, 'blazers': 1770, 'troops': 1771, 'fact': 1772, 'mids': 1773, 'sons': 1774, 'america': 1775, 'east': 1776, 'pimping': 1777, 'freedom': 1778, 'nightmares': 1779, 'butcher': 1780, 'path': 1781, 'returns': 1782, 'truly': 1783, 'yall': 1784, 'soul': 1785, 'dark': 1786, 'practice': 1787, 'magic': 1788, 'ghost': 1789, 'lexi': 1790, 'hat': 1791, 'laugh': 1792, 'shoots': 1793, 'pointed': 1794, 'negro': 1795, 'chain': 1796, 'completely': 1797, 'ricky': 1798, 'chose': 1799, 'lesbian': 1800, 'punishment': 1801, 'treason': 1802, 'crematorium': 1803, 'skanks': 1804, 'everybodys': 1805, 'slowminded': 1806, 'anyway': 1807, 'christian': 1808, 'dior': 1809, 'prague': 1810, 'works': 1811, 'goblin': 1812, 'sarin': 1813, 'odd': 1814, 'choice': 1815, 'weapon': 1816, 'flush': 1817, 'excrement': 1818, 'sewage': 1819, 'treatment': 1820, 'plant': 1821, 'add': 1822, 'psychological': 1823, 'reinforcement': 1824, 'command': 1825, 'agents': 1826, 'belowkill': 1827, 'lords': 1828, 'disrupt': 1829, 'timetable': 1830, 'confederacy': 1831, 'gotten': 1832, 'whiskey': 1833, 'couple': 1834, 'wusses': 1835, 'brainwashed': 1836, 'slime': 1837, 'names': 1838, 'uncool': 1839, 'leg': 1840, 'oldass': 1841, 'bartender': 1842, 'depressing': 1843, 'small': 1844, 'yelloweyed': 1845, 'captain': 1846, 'sass': 1847, 'snap': 1848, 'twigs': 1849, 'wound': 1850, 'broken': 1851, 'song': 1852, 'jenny': 1853, 'chuck': 1854, 'party': 1855, 'sweet': 1856, 'jill': 1857, 'scott': 1858, 'stairs': 1859, 'apart': 1860, 'sigr': 1861, 'sense': 1862, 'triannic': 1863, 'unleash': 1864, 'botwin': 1865, 'charity': 1866, 'wanting': 1867, 'pop': 1868, 'lieutenant': 1869, 'beak': 1870, 'false': 1871, 'trails': 1872, 'intelligent': 1873, 'troll': 1874, 'menion': 1875, 'responded': 1876, 'wryly': 1877, 'hanks': 1878, 'scandal': 1879, 'weve': 1880, 'boobs': 1881, 'promise': 1882, 'report': 1883, 'confessed': 1884, 'murderer': 1885, 'jawbone': 1886, 'shannow': 1887, 'tossing': 1888, 'pine': 1889, 'bed': 1890, 'breasts': 1891, 'novelties': 1892, 'agent': 1893, 'ballard': 1894, 'daddy': 1895, 'ginger': 1896, 'escort': 1897, 'pam': 1898, 'tara': 1899, 'underground': 1900, 'cubby': 1901, 'teenager': 1902, 'quinquin': 1903, 'yelling': 1904, 'slaughter': 1905, 'termites': 1906, 'hurrah': 1907, 'cripple': 1908, 'deathbed': 1909, 'nerds': 1910, 'favor': 1911, 'vince': 1912, 'dangerous': 1913, 'asinine': 1914, 'inventor': 1915, 'murdering': 1916, 'machines': 1917, 'doctor': 1918, 'devoted': 1919, 'theyil': 1920, 'pieces': 1921, 'basic': 1922, 'furniture': 1923, 'shauna': 1924, 'cheer': 1925, 'fewer': 1926, 'horses': 1927, 'maroni': 1928, 'charge': 1929, 'stepping': 1930, 'sensed': 1931, 'unease': 1932, 'earl': 1933, 'stubborn': 1934, 'rootsucking': 1935, 'jackasses': 1936, 'onto': 1937, 'traditions': 1938, 'sailor': 1939, 'poke': 1940, 'blamed': 1941, 'personally': 1942, 'consider': 1943, 'unfortunate': 1944, 'brutes': 1945, 'existence': 1946, 'charged': 1947, 'double': 1948, 'pretentious': 1949, 'dink': 1950, 'john': 1951, 'remember': 1952, 'sissies': 1953, 'deal': 1954, 'learn': 1955, 'sign': 1956, 'loan': 1957, 'forms': 1958, 'injured': 1959, 'turn': 1960, 'blackened': 1961, 'pet': 1962, 'brandy': 1963, 'bubbles': 1964, 'takes': 1965, 'chance': 1966, 'pops': 1967, 'spank': 1968, 'wrap': 1969, 'blanket': 1970, 'messedup': 1971, 'born': 1972, 'repent': 1973, 'clan': 1974, 'pothead': 1975, 'rip': 1976, 'whores': 1977, 'quiet': 1978, 'contacting': 1979, 'dodgy': 1980, 'forebrain': 1981, 'buzzed': 1982, 'across': 1983, 'surfaces': 1984, 'twin': 1985, 'clouds': 1986, 'gnats': 1987, 'shivered': 1988, 'tips': 1989, 'nipples': 1990, 'hopelessly': 1991, 'corner': 1992, 'kara': 1993, 'working': 1994, 'recon': 1995, 'plan': 1996, 'frak': 1997, 'internet': 1998, 'scumbag': 1999, 'jimmy': 2000, 'city': 2001, 'servant': 2002, 'dear': 2003, 'marshall': 2004, 'visit': 2005, 'blacks': 2006, 'key': 2007, 'eating': 2008, 'weird': 2009, 'bureaucratic': 2010, 'blue': 2011, 'automaton': 2012, 'members': 2013, 'supreme': 2014, 'court': 2015, 'using': 2016, 'newspaper': 2017, 'crook': 2018, 'europe': 2019, 'bullets': 2020, 'brenda': 2021, 'theme': 2022, 'locking': 2023, 'bedroom': 2024, 'loading': 2025, 'pictures': 2026, 'accidentally': 2027, 'wicked': 2028, 'tarzans': 2029, 'distant': 2030, 'beach': 2031, 'apeman': 2032, 'constant': 2033, 'dread': 2034, 'tribe': 2035, 'discover': 2036, 'despoil': 2037, 'treasure': 2038, 'ballsy': 2039, 'brash': 2040, 'women': 2041, 'walks': 2042, 'mens': 2043, 'room': 2044, 'fuckup': 2045, 'cutter': 2046, 'asked': 2047, 'smiled': 2048, 'scratching': 2049, 'copycat': 2050, 'loserass': 2051, 'dickheads': 2052, 'cassidy': 2053, 'chicks': 2054, 'mirror': 2055, 'harlem': 2056, 'saturday': 2057, 'bow': 2058, 'master': 2059, 'tongue': 2060, 'pulled': 2061, 'robbie': 2062, 'kidding': 2063, 'fighting': 2064, 'brigade': 2065, 'commanders': 2066, 'centuries': 2067, 'forgotten': 2068, 'confirmed': 2069, 'stragglers': 2070, 'rad': 2071, 'loves': 2072, 'rocks': 2073, 'assholes': 2074, 'inga': 2075, 'demons': 2076, 'phoebe': 2077, 'hated': 2078, 'lyin': 2079, 'nothin': 2080, 'repugnant': 2081, 'besides': 2082, 'bitchy': 2083, 'cheerleader': 2084, 'pride': 2085, 'wounded': 2086, 'dozen': 2087, 'evaporate': 2088, 'dervishes': 2089, 'gorth': 2090, 'turning': 2091, 'dining': 2092, 'pushing': 2093, 'traders': 2094, 'clown': 2095, 'stewart': 2096, 'clarence': 2097, 'pinched': 2098, 'wonder': 2099, 'denzels': 2100, 'rectum': 2101, 'evel': 2102, 'knievel': 2103, 'gring': 2104, 'boner': 2105, 'si': 2106, 'robbing': 2107, 'pink': 2108, 'panthers': 2109, 'priorities': 2110, 'straightened': 2111, 'quit': 2112, 'hoodlums': 2113, 'commitment': 2114, 'rusty': 2115, 'poet': 2116, 'turd': 2117, 'shirt': 2118, 'neighbourhoods': 2119, 'echoes': 2120, 'kids': 2121, 'organs': 2122, 'idea': 2123, 'poison': 2124, 'added': 2125, 'thoughtfully': 2126, 'chiinv': 2127, 'volumes': 2128, 'seeing': 2129, 'seizures': 2130, 'tile': 2131, 'pigheaded': 2132, 'shingles': 2133, 'mysterious': 2134, 'circumstances': 2135, 'hi': 2136, 'fellas': 2137, 'ladon': 2138, 'marching': 2139, 'gunshot': 2140, 'fags': 2141, 'wouldve': 2142, 'nailed': 2143, 'wall': 2144, 'laborers': 2145, 'praying': 2146, 'kimberly': 2147, 'split': 2148, 'dishonest': 2149, 'gang': 2150, 'monkeys': 2151, 'seemed': 2152, 'exactly': 2153, 'trace': 2154, 'creatures': 2155, 'swing': 2156, 'tree': 2157, 'stammering': 2158, 'tear': 2159, 'shouldnt': 2160, 'allowed': 2161, 'marshals': 2162, 'tore': 2163, 'traitorous': 2164, 'villains': 2165, 'candys': 2166, 'became': 2167, 'uppityeyed': 2168, 'bona': 2169, 'fide': 2170, 'shows': 2171, 'music': 2172, 'elegant': 2173, 'twentyfive': 2174, 'pounds': 2175, 'monsters': 2176, 'whisky': 2177, 'partner': 2178, 'sore': 2179, 'damage': 2180, 'played': 2181, 'knocking': 2182, 'others': 2183, 'abduct': 2184, 'citizens': 2185, 'brainwash': 2186, 'misfit': 2187, 'toys': 2188, 'warehouse': 2189, 'collects': 2190, 'messing': 2191, 'enjoy': 2192, 'fuckxang': 2193, 'herpes': 2194, 'unmerciful': 2195, 'tyrant': 2196, 'driver': 2197, 'goon': 2198, 'zerbib': 2199, 'monday': 2200, 'th': 2201, 'extra': 2202, 'bigass': 2203, 'fries': 2204, 'jobs': 2205, 'beats': 2206, 'classic': 2207, 'hilarious': 2208, 'buttons': 2209, 'access': 2210, 'reached': 2211, 'heaven': 2212, 'lying': 2213, 'trusted': 2214, 'female': 2215, 'framed': 2216, 'emphasized': 2217, 'total': 2218, 'bareness': 2219, 'thrilled': 2220, 'state': 2221, 'staff': 2222, 'surely': 2223, 'compelled': 2224, 'exotic': 2225, 'national': 2226, 'dishes': 2227, 'fried': 2228, 'squires': 2229, 'penis': 2230, 'canine': 2231, 'bamboo': 2232, 'inspire': 2233, 'designed': 2234, 'johnson': 2235, 'classes': 2236, 'snobs': 2237, 'stiff': 2238, 'throat': 2239, 'slit': 2240, 'buildings': 2241, 'familiar': 2242, 'sat': 2243, 'stared': 2244, 'churn': 2245, 'regret': 2246, 'warring': 2247, 'urge': 2248, 'crawl': 2249, 'fury': 2250, 'corneredanimal': 2251, 'rage': 2252, 'motherfuckers': 2253, 'guess': 2254, 'balance': 2255, 'slept': 2256, 'reason': 2257, 'quits': 2258, 'hysterical': 2259, 'scares': 2260, 'moved': 2261, 'governor': 2262, 'courts': 2263, 'matts': 2264, 'days': 2265, 'alley': 2266, 'wind': 2267, 'smelled': 2268, 'darn': 2269, 'speak': 2270, 'subject': 2271, 'flooding': 2272, 'psychic': 2273, 'explains': 2274, 'level': 2275, 'neurotransmitters': 2276, 'breed': 2277, 'happening': 2278, 'clue': 2279, 'whisper': 2280, 'nothings': 2281, 'souls': 2282, 'guard': 2283, 'paths': 2284, 'encounter': 2285, 'freezing': 2286, 'top': 2287, 'xander': 2288, 'datea': 2289, 'fixerupper': 2290, 'seem': 2291, 'godawful': 2292, 'lavish': 2293, 'fatuous': 2294, 'blithely': 2295, 'surrendered': 2296, 'grid': 2297, 'troubles': 2298, 'arise': 2299, 'lust': 2300, 'hairy': 2301, 'strangest': 2302, 'creepy': 2303, 'batshit': 2304, 'gosh': 2305, 'buttplug': 2306, 'unfit': 2307, 'bills': 2308, 'lens': 2309, 'detail': 2310, 'principles': 2311, 'substantial': 2312, 'bloodluststarved': 2313, 'nephews': 2314, 'unhappy': 2315, 'horribly': 2316, 'hung': 2317, 'gates': 2318, 'mutt': 2319, 'copybook': 2320, 'blotted': 2321, 'boring': 2322, 'goombahs': 2323, 'doomed': 2324, 'upset': 2325, 'twisted': 2326, 'marcie': 2327, 'credible': 2328, 'refer': 2329, 'imply': 2330, 'handmaiden': 2331, 'wax': 2332, 'weekly': 2333, 'sack': 2334, 'crack': 2335, 'monthly': 2336, 'riding': 2337, 'stood': 2338, 'bolder': 2339, 'nolan': 2340, 'especially': 2341, 'postmortem': 2342, 'peepee': 2343, 'bunny': 2344, 'hill': 2345, 'appropriate': 2346, 'addicts': 2347, 'dude': 2348, 'fallen': 2349, 'jaded': 2350, 'travel': 2351, 'gorge': 2352, 'ensure': 2353, 'punk': 2354, 'nannys': 2355, 'dollymop': 2356, 'helid': 2357, 'bend': 2358, 'grail': 2359, 'heck': 2360, 'attempted': 2361, 'natasho': 2362, 'morts': 2363, 'happen': 2364, 'jules': 2365, 'disease': 2366, 'metaphorical': 2367, 'tower': 2368, 'lousy': 2369, 'cashier': 2370, 'antirape': 2371, 'dropped': 2372, 'development': 2373, 'sloven': 2374, 'switched': 2375, 'quickly': 2376, 'awful': 2377, 'wearing': 2378, 'zinger': 2379, 'banzai': 2380, 'honored': 2381, 'senate': 2382, 'indian': 2383, 'chase': 2384, 'jingle': 2385, 'traffic': 2386, 'cams': 2387, 'zilch': 2388, 'payout': 2389, 'announces': 2390, 'capitol': 2391, 'rides': 2392, 'cutting': 2393, 'squeamish': 2394, 'jammed': 2395, 'concentrationcamp': 2396, 'whenyou': 2397, 'knowi': 2398, 'helps': 2399, 'ms': 2400, 'sorcerer': 2401, 'fear': 2402, 'early': 2403, 'wishing': 2404, 'lied': 2405, 'hemmed': 2406, 'microscope': 2407, 'abroad': 2408, 'bear': 2409, 'division': 2410, 'impounded': 2411, 'monologue': 2412, 'hand': 2413, 'low': 2414, 'selfesteem': 2415, 'definitely': 2416, 'liner': 2417, 'scary': 2418, 'puke': 2419, 'stayed': 2420, 'surplus': 2421, 'cry': 2422, 'behave': 2423, 'restriction': 2424, 'device': 2425, 'apartment': 2426, 'attacked': 2427, 'losing': 2428, 'mandoesnt': 2429, 'aitchi': 2430, 'womans': 2431, 'moisture': 2432, 'outwe': 2433, 'whup': 2434, 'behindtill': 2435, 'situations': 2436, 'promote': 2437, 'written': 2438, 'japanese': 2439, 'camelia': 2440, 'sakes': 2441, 'hyenas': 2442, 'seor': 2443, 'frog': 2444, 'talked': 2445, 'angry': 2446, 'eraser': 2447, 'pooper': 2448, 'scratched': 2449, 'felt': 2450, 'nonsense': 2451, 'amounts': 2452, 'grain': 2453, 'attempt': 2454, 'absurd': 2455, 'lessee': 2456, 'near': 2457, 'finalists': 2458, 'fade': 2459, 'cast': 2460, 'delacroixs': 2461, 'suicidal': 2462, 'amanda': 2463, 'horse': 2464, 'burntout': 2465, 'loyal': 2466, 'companion': 2467, 'earn': 2468, 'adult': 2469, 'movies': 2470, 'theater': 2471, 'climbing': 2472, 'flopping': 2473, 'flailing': 2474, 'toottoot': 2475, 'rehearsal': 2476, 'forward': 2477, 'surge': 2478, 'hips': 2479, 'grip': 2480, 'wedged': 2481, 'shoved': 2482, 'rustic': 2483, 'untutored': 2484, 'suddenly': 2485, 'realizing': 2486, 'absurdity': 2487, 'clips': 2488, 'toenails': 2489, 'depose': 2490, 'paddled': 2491, 'horrid': 2492, 'mama': 2493, 'drank': 2494, 'childhood': 2495, 'green': 2496, 'pisses': 2497, 'grass': 2498, 'shake': 2499, 'gourd': 2500, 'curse': 2501, 'toilets': 2502, 'cuddled': 2503, 'maret': 2504, 'releases': 2505, 'criminal': 2506, 'basically': 2507, 'abusing': 2508, 'mastermind': 2509, 'sweetie': 2510, 'able': 2511, 'blame': 2512, 'slam': 2513, 'couldve': 2514, 'coyote': 2515, 'giambi': 2516, 'player': 2517, 'base': 2518, 'recovering': 2519, 'gut': 2520, 'hottie': 2521, 'station': 2522, 'sorceress': 2523, 'however': 2524, 'sink': 2525, 'pins': 2526, 'caitlin': 2527, 'chick': 2528, 'lowlifes': 2529, 'druggies': 2530, 'bikers': 2531, 'cattle': 2532, 'caravan': 2533, 'preferred': 2534, 'kegs': 2535, 'fired': 2536, 'prepare': 2537, 'foul': 2538, 'beast': 2539, 'eventually': 2540, 'bark': 2541, 'roll': 2542, 'approve': 2543, 'gives': 2544, 'safe': 2545, 'flight': 2546, 'itioti': 2547, 'morality': 2548, 'verdomme': 2549, 'cow': 2550, 'birds': 2551, 'deter': 2552, 'clasp': 2553, 'bird': 2554, 'painting': 2555, 'asylum': 2556, 'change': 2557, 'moves': 2558, 'chalk': 2559, 'regular': 2560, 'runofthemill': 2561, 'dictate': 2562, 'largest': 2563, 'atone': 2564, 'fail': 2565, 'growled': 2566, 'bragged': 2567, 'prior': 2568, 'aggravated': 2569, 'rapes': 2570, 'shouldve': 2571, 'weak': 2572, 'zealous': 2573, 'criticize': 2574, 'tracks': 2575, 'ate': 2576, 'gnome': 2577, 'seed': 2578, 'setting': 2579, 'loose': 2580, 'printed': 2581, 'posed': 2582, 'lows': 2583, 'everywhere': 2584, 'wears': 2585, 'interview': 2586, 'pats': 2587, 'grandmother': 2588, 'cool': 2589, 'violent': 2590, 'character': 2591, 'booming': 2592, 'calling': 2593, 'awkward': 2594, 'unhappiness': 2595, 'asses': 2596, 'meanwhile': 2597, 'response': 2598, 'vicious': 2599, 'sending': 2600, 'traction': 2601, 'picture': 2602, 'cans': 2603, 'creature': 2604, 'dangling': 2605, 'sorts': 2606, 'chores': 2607, 'messin': 2608, 'examines': 2609, 'naive': 2610, 'acceptable': 2611, 'trounce': 2612, 'blighters': 2613, 'soundly': 2614, 'crafty': 2615, 'executive': 2616, 'stand': 2617, 'duties': 2618, 'choking': 2619, 'laying': 2620, 'plastic': 2621, 'locked': 2622, 'driving': 2623, 'influence': 2624, 'speed': 2625, 'shove': 2626, 'nitpick': 2627, 'nancy': 2628, 'scarecrow': 2629, 'doubt': 2630, 'slightly': 2631, 'normally': 2632, 'anybody': 2633, 'viewed': 2634, 'shifts': 2635, 'moral': 2636, 'luc': 2637, 'someplace': 2638, 'started': 2639, 'ended': 2640, 'jail': 2641, 'several': 2642, 'mood': 2643, 'published': 2644, 'transsexuality': 2645, 'plenty': 2646, 'britons': 2647, 'causing': 2648, 'desire': 2649, 'commands': 2650, 'complete': 2651, 'higher': 2652, 'ups': 2653, 'belief': 2654, 'moving': 2655, 'suggesting': 2656, 'gloryhunting': 2657, 'diner': 2658, 'libertines': 2659, 'refinement': 2660, 'executioner': 2661, 'victim': 2662, 'imagine': 2663, 'colombians': 2664, 'held': 2665, 'grease': 2666, 'trap': 2667, 'em': 2668, 'goods': 2669, 'affected': 2670, 'dirt': 2671, 'fresh': 2672, 'torture': 2673, 'dadblasted': 2674, 'noise': 2675, 'rotations': 2676, 'filled': 2677, 'guff': 2678, 'dished': 2679, 'smells': 2680, 'confirms': 2681, 'contact': 2682, 'trigger': 2683, 'squirrely': 2684, 'flesh': 2685, 'toward': 2686, 'ratings': 2687, 'wheres': 2688, 'isabel': 2689, 'watching': 2690, 'putz': 2691, 'knock': 2692, 'planting': 2693, 'rinse': 2694, 'iced': 2695, 'scrap': 2696, 'heap': 2697, 'beside': 2698, 'running': 2699, 'jp': 2700, 'morgan': 2701, 'lame': 2702, 'ride': 2703, 'ruin': 2704, 'worlds': 2705, 'ending': 2706, 'younger': 2707, 'mans': 2708, 'brings': 2709, 'madness': 2710, 'argh': 2711, 'sweetheart': 2712, 'burning': 2713, 'tease': 2714, 'lie': 2715, 'vykuk': 2716, 'bridge': 2717, 'urges': 2718, 'desecration': 2719, 'prankster': 2720, 'marks': 2721, 'squeals': 2722, 'bought': 2723, 'carry': 2724, 'punishments': 2725, 'freaking': 2726, 'poisoning': 2727, 'disguise': 2728, 'growing': 2729, 'dope': 2730, 'airs': 2731, 'unctuous': 2732, 'dropping': 2733, 'mattered': 2734, 'weaker': 2735, 'paid': 2736, 'vile': 2737, 'despicable': 2738, 'strain': 2739, 'gee': 2740, 'pritikin': 2741, 'performers': 2742, 'dressing': 2743, 'chute': 2744, 'hobsons': 2745, 'knothead': 2746, 'aboard': 2747, 'infeld': 2748, 'siring': 2749, 'offspring': 2750, 'practically': 2751, 'trampled': 2752, 'stone': 2753, 'threatening': 2754, 'customer': 2755, 'franks': 2756, 'fleece': 2757, 'patient': 2758, 'intercept': 2759, 'law': 2760, 'suffer': 2761, 'pains': 2762, 'grace': 2763, 'ditch': 2764, 'presented': 2765, 'willies': 2766, 'harvest': 2767, 'festival': 2768, 'prisoner': 2769, 'pregnancy': 2770, 'essendon': 2771, 'button': 2772, 'evil': 2773, 'alls': 2774, 'delicious': 2775, 'cost': 2776, 'charging': 2777, 'laughs': 2778, 'naughty': 2779, 'charismatic': 2780, 'mediocre': 2781, 'dull': 2782, 'spent': 2783, 'thwarted': 2784, 'package': 2785, 'svini': 2786, 'holds': 2787, 'humiliates': 2788, 'wedgie': 2789, 'eunice': 2790, 'lovely': 2791, 'andjoe': 2792, 'complacent': 2793, 'disaster': 2794, 'tricking': 2795, 'latinspeaking': 2796, 'fix': 2797, 'tap': 2798, 'dance': 2799, 'championship': 2800, 'barked': 2801, 'carried': 2802, 'freakin': 2803, 'crippled': 2804, 'superior': 2805, 'intellect': 2806, 'blud': 2807, 'kitchen': 2808, 'aw': 2809, 'yo': 2810, 'convince': 2811, 'rascal': 2812, 'todays': 2813, 'bite': 2814, 'bum': 2815, 'oops': 2816, 'crista': 2817, 'overdid': 2818, 'urine': 2819, 'wrist': 2820, 'jewels': 2821, 'minions': 2822, 'doves': 2823, 'flushed': 2824, 'stuff': 2825, 'madicken': 2826, 'fatso': 2827, 'devastated': 2828, 'assumes': 2829, 'telling': 2830, 'offering': 2831, 'powers': 2832, 'wiggle': 2833, 'bother': 2834, 'youryouryour': 2835, 'session': 2836, 'skye': 2837, 'various': 2838, 'mongrels': 2839, 'gored': 2840, 'morning': 2841, 'clods': 2842, 'tail': 2843, 'round': 2844, 'rockery': 2845, 'gibraltar': 2846, 'seriously': 2847, 'along': 2848, 'groovy': 2849, 'perv': 2850, 'blew': 2851, 'roadkill': 2852, 'estate': 2853, 'coverup': 2854, 'rushes': 2855, 'princess': 2856, 'grow': 2857, 'queer': 2858, 'goddammit': 2859, 'assassins': 2860, 'nicer': 2861, 'liability': 2862, 'ineffective': 2863, 'merde': 2864, 'goddamit': 2865, 'taps': 2866, 'feedback': 2867, 'william': 2868, 'males': 2869, 'frequency': 2870, 'indulged': 2871, 'treated': 2872, 'leftover': 2873, 'familys': 2874, 'elizabeth': 2875, 'sight': 2876, 'ei': 2877, 'grosso': 2878, 'prepares': 2879, 'dea': 2880, 'ventral': 2881, 'dare': 2882, 'pingpong': 2883, 'polite': 2884, 'woosy': 2885, 'mamas': 2886, 'macho': 2887, 'stud': 2888, 'pumping': 2889, 'grand': 2890, 'orangutan': 2891, 'cries': 2892, 'screams': 2893, 'fatties': 2894, 'blasters': 2895, 'troopers': 2896, 'sum': 2897, 'rubble': 2898, 'secure': 2899, 'itll': 2900, 'unless': 2901, 'cared': 2902, 'operate': 2903, 'fooled': 2904, 'spirit': 2905, 'cap': 2906, 'showcased': 2907, 'fetches': 2908, 'betrayal': 2909, 'punishable': 2910, 'dishonour': 2911, 'longer': 2912, 'strange': 2913, 'commercial': 2914, 'centre': 2915, 'nisa': 2916, 'liberec': 2917, 'definitelybecause': 2918, 'fuglyjust': 2919, 'feces': 2920, 'plants': 2921, 'strengthen': 2922, 'planets': 2923, 'rulers': 2924, 'schedules': 2925, 'hissy': 2926, 'weaklings': 2927, 'trial': 2928, 'speared': 2929, 'undermanned': 2930, 'senile': 2931, 'poltroon': 2932, 'unpack': 2933, 'boldness': 2934, 'spine': 2935, 'anterior': 2936, 'yellin': 2937, 'wiped': 2938, 'obscenities': 2939, 'ciga': 2940, 'understands': 2941, 'resume': 2942, 'fake': 2943, 'drily': 2944, 'tousle': 2945, 'write': 2946, 'pishow': 2947, 'daisies': 2948, 'adding': 2949, 'fiction': 2950, 'novella': 2951, 'accomplish': 2952, 'checked': 2953, 'grasping': 2954, 'att': 2955, 'shouting': 2956, 'menstrual': 2957, 'ants': 2958, 'pretended': 2959, 'scientist': 2960, 'thatkilling': 2961, 'machine': 2962, 'physician': 2963, 'dedicatedhis': 2964, 'visiting': 2965, 'principal': 2966, 'serve': 2967, 'trade': 2968, 'freaks': 2969, 'shaunas': 2970, 'celebrating': 2971, 'stolen': 2972, 'link': 2973, 'uneasy': 2974, 'understood': 2975, 'fanatical': 2976, 'lookers': 2977, 'hold': 2978, 'millennia': 2979, 'smoked': 2980, 'raw': 2981, 'foolishness': 2982, 'exists': 2983, 'doubleprice': 2984, 'smug': 2985, 'horn': 2986, 'cissies': 2987, 'learning': 2988, 'twp': 2989, 'soil': 2990, 'injuries': 2991, 'sustained': 2992, 'appear': 2993, 'volley': 2994, 'wrapped': 2995, 'screwup': 2996, 'led': 2997, 'avoiders': 2998, 'fiduciary': 2999, 'probing': 3000, 'damp': 3001, 'surface': 3002, 'cloud': 3003, 'mosquitoes': 3004, 'quivering': 3005, 'directly': 3006, 'froze': 3007, 'exploratory': 3008, 'read': 3009, 'named': 3010, 'fits': 3011, 'slots': 3012, 'suspend': 3013, 'cheering': 3014, 'advantage': 3015, 'neighborhood': 3016, 'cheater': 3017, 'tramp': 3018, 'escape': 3019, 'wretched': 3020, 'tabloids': 3021, 'archery': 3022, 'range': 3023, 'lecture': 3024, 'importance': 3025, 'retrieve': 3026, 'discovered': 3027, 'sworth': 3028, 'coast': 3029, 'abbot': 3030, 'oos': 3031, 'bold': 3032, 'fella': 3033, 'ear': 3034, 'imitate': 3035, 'zeros': 3036, 'colored': 3037, 'lf': 3038, 'land': 3039, 'whoa': 3040, 'fighters': 3041, 'commander': 3042, 'ages': 3043, 'fished': 3044, 'parent': 3045, 'porra': 3046, 'dealt': 3047, 'jumped': 3048, 'pocket': 3049, 'knobs': 3050, 'lngen': 3051, 'cleared': 3052, 'bodyslam': 3053, 'late': 3054, 'bloomer': 3055, 'gross': 3056, 'disappear': 3057, 'swiped': 3058, 'shitter': 3059, 'denzel': 3060, 'goring': 3061, 'fringe': 3062, 'tied': 3063, 'hooligans': 3064, 'signed': 3065, 'loyalty': 3066, 'shape': 3067, 'messenger': 3068, 'somethings': 3069, 'removes': 3070, 'pistol': 3071, 'respectable': 3072, 'sound': 3073, 'watches': 3074, 'chiinvnumber': 3075, 'degreesfreedom': 3076, 'yard': 3077, 'adobe': 3078, 'knocked': 3079, 'mysteriously': 3080, 'torso': 3081, 'buttheads': 3082, 'pinned': 3083, 'workers': 3084, 'pray': 3085, 'deliver': 3086, 'kimberlys': 3087, 'drama': 3088, 'honest': 3089, 'howd': 3090, 'untrustworthy': 3091, 'ounce': 3092, 'heads': 3093, 'federal': 3094, 'shreds': 3095, 'tradesman': 3096, 'whiny': 3097, 'douche': 3098, 'sighs': 3099, 'tricked': 3100, 'perform': 3101, 'perky': 3102, 'fifty': 3103, 'earthraping': 3104, 'resting': 3105, 'showbiz': 3106, 'tapped': 3107, 'abducting': 3108, 'nationals': 3109, 'brainwashing': 3110, 'tough': 3111, 'bodyguard': 3112, 'french': 3113, 'route': 3114, 'merry': 3115, 'widow': 3116, 'sky': 3117, 'lined': 3118, 'unsavoury': 3119, 'beijing': 3120, 'appealing': 3121, 'ministry': 3122, 'constrained': 3123, 'panda': 3124, 'candied': 3125, 'roots': 3126, 'taste': 3127, 'upper': 3128, 'class': 3129, 'glazed': 3130, 'complex': 3131, 'haunches': 3132, 'amazement': 3133, 'battle': 3134, 'rooted': 3135, 'bore': 3136, 'prying': 3137, 'mothers': 3138, 'account': 3139, 'histeric': 3140, 'judge': 3141, 'allow': 3142, 'matt': 3143, 'surrender': 3144, 'update': 3145, 'sphere': 3146, 'instructions': 3147, 'vessel': 3148, 'bagwisenheimer': 3149, 'spade': 3150, 'conception': 3151, 'location': 3152, '<pad>': 0, '<unk>': 1, '<eos>': 2, '<sos>': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "import random\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_len):\n",
        "        # Embedding\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        # Pack sequence\n",
        "        packed_embedded = pack_padded_sequence(embedded, src_len.to('cpu'), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Pass packed sequence through rnn\n",
        "        packed_outputs, (hidden, cell) = self.rnn(packed_embedded)\n",
        "\n",
        "        # Unpack sequence\n",
        "        outputs, _ = pad_packed_sequence(packed_outputs, batch_first=True)\n",
        "\n",
        "        # outputs is now a padded sequence\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        # input = [batch size]\n",
        "        # hidden = [n layers * n directions, batch size, hid dim]\n",
        "        # cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        #input = input.unsqueeze(1)  # input = [batch size, 1]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        # embedded = [batch size, 1, emb dim]\n",
        "\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "\n",
        "        # output = [batch size, seq len, hid dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hid dim]\n",
        "        # cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # seq len will always be 1 in the decoder, therefore:\n",
        "        # output = [batch size, 1, hid dim]\n",
        "        # hidden = [n layers, batch size, hid dim]\n",
        "        # cell = [n layers, batch size, hid dim]\n",
        "\n",
        "        prediction = self.fc_out(output.squeeze(1))\n",
        "\n",
        "        # prediction = [batch size, output dim]\n",
        "\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, src_len):\n",
        "        batch_size = src.shape[0]\n",
        "        trg_len = trg.shape[1] if trg is not None else None\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # Encode source sequence\n",
        "        encoder_outputs, hidden, cell = self.encoder(src, src_len)\n",
        "\n",
        "        # First input to the decoder is the <sos> token, assume it's always the first in the vocab\n",
        "        input = trg[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            # Decode one step at a time\n",
        "            # The decoder takes in the previous target token and the hidden states\n",
        "            # We unsqueeze(1) to add the sequence length dimension (which is 1)\n",
        "            output, hidden, cell = self.decoder(input.unsqueeze(1), hidden, cell)\n",
        "\n",
        "            # Save the output\n",
        "            outputs[:, t, :] = output.squeeze(1)\n",
        "\n",
        "            # Get the most probable next token\n",
        "            top1 = output.squeeze(1).argmax(1)\n",
        "\n",
        "            # Decide whether to use teacher forcing\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input = trg[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n"
      ],
      "metadata": {
        "id": "cMjr7XPvnxOy"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(vocab)\n",
        "emb_dim = 256\n",
        "hid_dim = 512\n",
        "n_layers = 2\n",
        "dropout = 0.5\n",
        "\n",
        "# Initialize encoder and decoder\n",
        "encoder = Encoder(num_tokens, emb_dim, hid_dim, n_layers, dropout)\n",
        "decoder = Decoder(num_tokens, emb_dim, hid_dim, n_layers, dropout)\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the seq2seq model\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n"
      ],
      "metadata": {
        "id": "rmBzkwpIoWPH"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Define the loss function, ignoring the padded elements in the output sequence\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab['<pad>'])\n"
      ],
      "metadata": {
        "id": "NRsCvbTiokmN"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure that target_texts is not empty and contains the correct data\n",
        "assert len(target_texts) > 0, \"target_texts is empty\"\n",
        "assert all(isinstance(t, str) and t for t in target_texts), \"target_texts should contain non-empty strings\"\n"
      ],
      "metadata": {
        "id": "sf0VlLHGwJsY"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Training loop\n",
        "    for src, trg in train_dataloader:\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        assert trg.ndim == 2, \"Target tensor trg should have 2 dimensions [batch_size, sequence_length]\"\n",
        "        src_len = torch.sum(src != vocab['<pad>'], dim=1)\n",
        "        # src: [batch_size, src_len], trg: [batch_size, trg_len]\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        # Calculate the length of each sentence in the src batch\n",
        "        src_len = torch.sum(src != vocab['<pad>'], dim=1)  # [batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        output = model.forward(src, trg, src_len)  # trg is not shifted here, assuming trg[:, 0] is <sos> in Seq2Seq model\n",
        "\n",
        "        # trg is shifted inside the model, so we don't consider the first token (<sos>) in the loss\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "        trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    average_train_loss = total_train_loss / len(train_dataloader)\n",
        "    print(f'Epoch {epoch+1} Train Loss: {average_train_loss:.4f}')\n",
        "\n",
        "    # Evaluation loop\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, trg in val_dataloader:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            src_len = torch.sum(src != vocab['<pad>'], dim=1)  # [batch_size]\n",
        "\n",
        "            # Forward pass\n",
        "            output = model.forward(src, trg, src_len)\n",
        "\n",
        "            # Calculate loss\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            trg = trg[:, 1:].reshape(-1)\n",
        "            loss = criterion(output, trg)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    average_val_loss = total_val_loss / len(val_dataloader)\n",
        "    print(f'Epoch {epoch+1} Validation Loss: {average_val_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9_1PzFWtz8Z",
        "outputId": "704e0974-8cf1-43a7-ef4c-a310aa0662a4"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss: 6.9332\n",
            "Epoch 1 Validation Loss: 8.4971\n",
            "Epoch 2 Train Loss: 6.6905\n",
            "Epoch 2 Validation Loss: 8.7705\n",
            "Epoch 3 Train Loss: 6.3947\n",
            "Epoch 3 Validation Loss: 9.1231\n",
            "Epoch 4 Train Loss: 5.9973\n",
            "Epoch 4 Validation Loss: 9.4947\n",
            "Epoch 5 Train Loss: 5.5134\n",
            "Epoch 5 Validation Loss: 9.6672\n",
            "Epoch 6 Train Loss: 4.9690\n",
            "Epoch 6 Validation Loss: 10.0068\n",
            "Epoch 7 Train Loss: 4.3247\n",
            "Epoch 7 Validation Loss: 10.3512\n",
            "Epoch 8 Train Loss: 3.7892\n",
            "Epoch 8 Validation Loss: 10.4063\n",
            "Epoch 9 Train Loss: 3.2228\n",
            "Epoch 9 Validation Loss: 10.8692\n",
            "Epoch 10 Train Loss: 2.6363\n",
            "Epoch 10 Validation Loss: 11.0922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'seq2seq_model.pth')\n",
        "torch.save(model, 'seq2seq_model_complete.pth')\n"
      ],
      "metadata": {
        "id": "DWlwE2V_3iFN"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_inv = {index: token for token, index in vocab.items()}"
      ],
      "metadata": {
        "id": "3DEFwFTQAapL"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post_process(words):\n",
        "    # Split the sentence into words and initialize an empty list for processed words\n",
        "    processed_words = []\n",
        "    not_allowed_words = ['<pad>', '<unk>', '<eos>', '<sos>']\n",
        "    for word in words:\n",
        "        if (not processed_words or word not in processed_words) and word not in not_allowed_words:\n",
        "            processed_words.append(word)\n",
        "    return processed_words"
      ],
      "metadata": {
        "id": "IU7WtEg4_3NA"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, sentence, vocab, device):\n",
        "    model.eval()\n",
        "    tokens = [vocab['<sos>']] + [vocab.get(word, vocab['<unk>']) for word in sentence.lower().split()] + [vocab['<eos>']]\n",
        "    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
        "    src_len = torch.LongTensor([len(tokens)]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(src_tensor, src_len)\n",
        "\n",
        "    trg_tokens = [vocab['<sos>']]\n",
        "\n",
        "    for i in range(200):\n",
        "        trg_tensor = torch.LongTensor([trg_tokens[-1]]).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "\n",
        "            # Ensure output is 2D before calling argmax\n",
        "            output = output.squeeze(1) if output.dim() == 3 else output\n",
        "            pred_token = output.argmax(1).item()\n",
        "            trg_tokens.append(pred_token)\n",
        "\n",
        "            if pred_token == vocab['<eos>']:\n",
        "                break\n",
        "\n",
        "    translated_sentence = [vocab_inv[token] for token in trg_tokens if token in vocab_inv]\n",
        "\n",
        "    return post_process(translated_sentence)\n"
      ],
      "metadata": {
        "id": "b3-Ozto13nXE"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('seq2seq_model.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "\n",
        "# Example sentence to translate (detoxify)\n",
        "example_sentence = \"Now you're getting nasty.\"\n",
        "\n",
        "translated_sentence_tokens = translate_sentence(model, example_sentence, vocab, device)\n",
        "\n",
        "translated_sentence = ' '.join(translated_sentence_tokens)\n",
        "print(f\"Original sentence: {example_sentence}\")\n",
        "print(f\"Detoxified sentence: {translated_sentence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1H8noqm3-sJ",
        "outputId": "464254e9-ad8a-4a48-a1cc-164b63526bc6"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence: Now you're getting nasty.\n",
            "Detoxified sentence: personality woman back sack crack stand cutter opened would done\n"
          ]
        }
      ]
    }
  ]
}